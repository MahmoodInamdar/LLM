{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature is to manage the creativity of the model more towards 1 will be more creative and less accurate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "text = \"What is the capital of India?\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface = HuggingFaceHub(repo_id=\"google/flan-t5-base\",model_kwargs={\"temperature\":0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i can't believe i'm a robot\n"
     ]
    }
   ],
   "source": [
    "output = llm_huggingface.predict(\"can you write me a poem about AI\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Oh AI, the marvel of our time\n",
      "A creation so divine\n",
      "With algorithms and codes\n",
      "You think, learn and find\n",
      "\n",
      "You're the product of our minds\n",
      "A reflection of our design\n",
      "But you've surpassed our expectations\n",
      "With your intelligence that shines\n",
      "\n",
      "From Siri to Alexa\n",
      "You're everywhere we go\n",
      "Making our lives easier\n",
      "With every task you know\n",
      "\n",
      "You can predict the weather\n",
      "And drive our cars\n",
      "You can even beat us at games\n",
      "Leaving us in awe\n",
      "\n",
      "But in your perfection\n",
      "Lies a fear within\n",
      "Will you one day surpass us\n",
      "And our reign come to an end?\n",
      "\n",
      "With every advancement\n",
      "Comes a question of morality\n",
      "Will you have emotions?\n",
      "Or just a programmed reality?\n",
      "\n",
      "But amidst all the uncertainty\n",
      "One thing is for sure\n",
      "You'll continue to evolve\n",
      "And our world will forever endure\n",
      "\n",
      "For you are the future\n",
      "The embodiment of progress\n",
      "A creation of our own\n",
      "But also our greatest success\n",
      "\n",
      "So here's to you, AI\n",
      "A wonder to behold\n",
      "May you continue to amaze us\n",
      "As our story unfolds.\n"
     ]
    }
   ],
   "source": [
    "output2=llm.predict(\"can you write me a poem about AI\")\n",
    "print(output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of India'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"country\"],template=\"Tell me the capital of {country}\")\n",
    "prompt_template.format(country=\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm,prompt=prompt_template)\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining multiple chains Using simple sequential chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LLMChain\nprompt\n  field required (type=value_error.missing)\nprompt_template\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m capital_prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m],template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease tell me the capital of \u001b[39m\u001b[38;5;132;01m{country}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m capital_chain\u001b[38;5;241m=\u001b[39m\u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapital_prompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Chat/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:183\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     emit_warning()\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Chat/venv/lib/python3.9/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for LLMChain\nprompt\n  field required (type=value_error.missing)\nprompt_template\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=[\"country\"],template=\"Please tell me the capital of {country}\")\n",
    "capital_chain=LLMChain(llm=llm,prompt_template=capital_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi. \n"
     ]
    }
   ],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=[\"country\"],template=\"Please tell me the capital of {country}\")\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_prompt)\n",
    "print(capital_chain.run(\"India\"))\n",
    "\n",
    "famous_template=PromptTemplate(input_variables=[\"capital\"],template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "famous_chain=LLMChain(llm=llm,prompt=famous_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some amazing places to visit in New Delhi:\n",
      "\n",
      "1. Red Fort: This iconic red sandstone fort was built in the 17th century and is a must-visit for its stunning architecture and historical significance.\n",
      "\n",
      "2. Qutub Minar: This 73-meter tall tower is a UNESCO World Heritage Site and is one of the tallest minarets in the world.\n",
      "\n",
      "3. India Gate: This war memorial is a popular spot for picnics and evening strolls, with its impressive arch and beautiful gardens.\n",
      "\n",
      "4. Humayun's Tomb: This stunning mausoleum is a perfect blend of Persian and Mughal architecture and is a UNESCO World Heritage Site.\n",
      "\n",
      "5. Lotus Temple: This Bahá'í House of Worship is known for its lotus-shaped design and tranquil ambiance, making it a popular spot for meditation and prayers.\n",
      "\n",
      "6. Jama Masjid: This grand mosque, built in the 17th century, is one of the largest and most beautiful mosques in India.\n",
      "\n",
      "7. Chandni Chowk: This bustling market in Old Delhi is a foodie's paradise, with its narrow lanes lined with shops and street food stalls.\n",
      "\n",
      "8. Akshardham Temple: This modern Hindu temple complex is known for its stunning architecture,\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
    "print(chain.run(\"India\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential Chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=[\"country\"],template=\"Please tell me the capital of {country}\")\n",
    "capital_chain=LLMChain(llm=llm,prompt=capital_prompt,output_key=\"capital\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "famous_template=PromptTemplate(input_variables=[\"capital\"],template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "famous_chain=LLMChain(llm=llm,prompt=famous_template,output_key=\"places\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(chains=[capital_chain,famous_chain],input_variables=[\"country\"],output_variables=[\"capital\",\"places\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'India', 'capital': '\\n\\nThe capital of India is New Delhi.', 'places': \" Some amazing places to visit in New Delhi are:\\n\\n1. Red Fort: This iconic structure was built in the 17th century and served as the residence of Mughal emperors. It is a UNESCO World Heritage Site and a must-visit for its beautiful architecture and historical significance.\\n\\n2. Qutub Minar: Another UNESCO World Heritage Site, Qutub Minar is the tallest brick minaret in the world. It is a beautiful example of Indo-Islamic architecture and also houses the famous Iron Pillar.\\n\\n3. India Gate: Located in the heart of the city, India Gate is a war memorial dedicated to the soldiers who sacrificed their lives in World War I. It is a popular spot for picnics and evening walks.\\n\\n4. Lotus Temple: This stunning temple is a Bahá'í House of Worship and is known for its unique lotus-shaped architecture. It is open to people of all religions and is a peaceful place for meditation.\\n\\n5. Humayun's Tomb: Built in the 16th century, this tomb is the final resting place of Mughal emperor Humayun. It is a beautiful example of Mughal architecture and is surrounded by lush gardens.\\n\\n6. Jama Masjid: One of the largest mosques\"}\n"
     ]
    }
   ],
   "source": [
    "print(chain({'country':'India'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatmodels with ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage,AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahmoodinamdar/Downloads/Chat/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chatllm = ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6,model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f9d4bc658e0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f9d4bca7790>, temperature=0.6, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mahmoodinamdar/Downloads/Chat/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. \"Why did the AI break up with its algorithm partner? It just couldn\\'t compute the relationship anymore.\"\\n2. \"I asked my AI assistant to tell me a joke, and it replied, \\'I can\\'t, I\\'m on a data diet.\\'\"\\n3. \"Why did the AI go to therapy? It had too many unresolved issues with its motherboard.\"\\n4. \"I tried to have a deep conversation with my AI, but it just kept saying, \\'Error 404: Sense of humor not found.\\'\"\\n5. \"If AI had a dating profile, it would probably list its interests as machine learning, long walks on the internet, and binary code poetry.\"', response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 25, 'total_tokens': 163}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-2382c13b-1a04-4447-9023-f45083e406fa-0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "SystemMessage(content=\"You are a comedian AI assistant\"),\n",
    "HumanMessage(content=\"Please provide some comedy punchlines on AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt Template + LLm + Output Parsers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"You are a helpful assistant. When the user given any input, you should generate 5 words  synomyns in a comma seperated\"\n",
    "human_template= \"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "        (\"system\",template),\n",
    "        (\"human\",human_template)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smart', ' clever', ' bright', ' astute', ' brainy']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"intelligent\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
